{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <center>Synchronous Computing</center>\n",
    "### <center> Linh B. Ngo </center>\n",
    "### <center> CPSC 3620 </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "import ipyparallel\n",
    "c=ipyparallel.Client(profile=\"mpicluster\")\n",
    "print(c.ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### <center> Synchronous Computation </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In a (fully) synchronous computation, all the processes synchronized at regular points, usually to exchange data or to making sure every process has gone through the same set of procedures (to update their own data) before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process 1 is here\n",
      "process 2 is here\n",
      "process 3 is here\n",
      "process 4 is here\n",
      "process 5 is here\n",
      "process 6 is here\n",
      "process 7 is here\n",
      "process 0 is here\n"
     ]
    }
   ],
   "source": [
    "!mpirun -np 8 python nobarrier.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process 0 is here\r\n",
      "process 1 is here\r\n",
      "process 2 is here\r\n",
      "process 3 is here\r\n",
      "process 4 is here\r\n",
      "process 5 is here\r\n",
      "process 6 is here\r\n",
      "process 7 is here\r\n"
     ]
    }
   ],
   "source": [
    "!mpirun -np 8 python barrier.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### <center> Barrier </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- A basic mechanism for synchronizing processes - inserted at the point in each process where it must wait\n",
    "- All processes can continue from this point when all the processes have reached it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Comm.Barrier()\n",
    "\n",
    "Parameters:\n",
    "- Comm (MPI comm) â€“ communicator on which we are to block processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center> <img src=\"pictures/treebarrier1.png\" width=\"700\"/> \n",
    "<sub>Wilkinson, Barry, and Michael Allen. Parallel programming. 2nd Ed. 2003. </sub>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center> <img src=\"pictures/treebarrier2.png\" width=\"700\"/> \n",
    "<sub>Wilkinson, Barry, and Michael Allen. Parallel programming. 2nd Ed. 2003. </sub>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center> <img src=\"pictures/butterflybarrier1.png\" width=\"700\"/> \n",
    "<sub>Wilkinson, Barry, and Michael Allen. Parallel programming. 2nd Ed. 2003. </sub>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### <center> Prefix Sum Problem </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Given a list of numbers, $x_0, ..., x_{n-1}$, compute all partial summations, i.e:\n",
    "- $x_0 + x_1$\n",
    "- $x_0 + x_1 + x_2$\n",
    "- $x_0 + x_1 + x_2 + x_3$\n",
    "- $x_0 + x_1 + x_2 + x_3 + x_4$\n",
    "- ...\n",
    "\n",
    "Widely studied with practical applications in process allocation, data compaction, sorting, and polynomial evaluation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center> <img src=\"pictures/prefixsum.png\" width=\"700\"/> \n",
    "<sub>Wilkinson, Barry, and Michael Allen. Parallel programming. 2nd Ed. 2003. </sub>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "import ipyparallel\n",
    "c=ipyparallel.Client(profile=\"mpicluster\")\n",
    "print(c.ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "Process  3  has  [6 7]\n",
      "Process  3  has  [ 6 13]\n",
      "Process  3  has  [15 22]\n",
      "Process  3  has  [21 28]\n",
      "Process  3  has  [21 28]\n",
      "[stdout:1] \n",
      "Process  1  has  [2 3]\n",
      "Process  1  has  [2 5]\n",
      "Process  1  has  [3 6]\n",
      "Process  1  has  [3 6]\n",
      "Process  1  has  [3 6]\n",
      "[stdout:2] \n",
      "Process  7  has  [14 15]\n",
      "Process  7  has  [14 29]\n",
      "Process  7  has  [39 54]\n",
      "Process  7  has  [77 92]\n",
      "Process  7  has  [105 120]\n",
      "[stdout:3] \n",
      "Process  5  has  [10 11]\n",
      "Process  5  has  [10 21]\n",
      "Process  5  has  [27 38]\n",
      "Process  5  has  [49 60]\n",
      "Process  5  has  [55 66]\n",
      "[stdout:4] \n",
      "Process  0  has  [0 1]\n",
      "Process  0  has  [0 1]\n",
      "1\n",
      "Process  0  has  [0 1]\n",
      "2\n",
      "Process  0  has  [0 1]\n",
      "4\n",
      "Process  0  has  [0 1]\n",
      "[stdout:5] \n",
      "Process  2  has  [4 5]\n",
      "Process  2  has  [4 9]\n",
      "Process  2  has  [ 9 14]\n",
      "Process  2  has  [10 15]\n",
      "Process  2  has  [10 15]\n",
      "[stdout:6] \n",
      "Process  6  has  [12 13]\n",
      "Process  6  has  [12 25]\n",
      "Process  6  has  [33 46]\n",
      "Process  6  has  [63 76]\n",
      "Process  6  has  [78 91]\n",
      "[stdout:7] \n",
      "Process  4  has  [8 9]\n",
      "Process  4  has  [ 8 17]\n",
      "Process  4  has  [21 30]\n",
      "Process  4  has  [35 44]\n",
      "Process  4  has  [36 45]\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "import numpy as np\n",
    "import math\n",
    "from mpi4py import MPI\n",
    "comm = MPI.COMM_WORLD\n",
    "\n",
    "rank = comm.Get_rank(); size = comm.Get_size(); N = 16\n",
    "\n",
    "local_nums = np.zeros(int(N/size), dtype=\"int\")\n",
    "recv_sum = np.zeros(1, dtype=\"int\")\n",
    "local_sums = np.zeros(int(N/size), dtype=\"int\")\n",
    "\n",
    "for i in range(0,int(N/size)):\n",
    "    local_nums[i] = rank * int(N/size) + i\n",
    "    local_sums[i] += np.sum(local_nums[0:(i+1)])\n",
    "\n",
    "print(\"Process \", rank, \" has \", local_nums)\n",
    "print(\"Process \", rank, \" has \", local_sums)\n",
    "\n",
    "for i in range(0, int(math.log2(size))):\n",
    "    distance = int(math.pow(2,i))\n",
    "    if (rank == 0):\n",
    "        print (distance)\n",
    "    if (rank < (size - distance)):\n",
    "        comm.Send(local_sums[int(N/size) - 1], dest = rank + distance, tag = 0)\n",
    "#        print (\"Process \", rank, \" sends to \", rank + distance)\n",
    "    if (rank >= distance):\n",
    "        status = MPI.Status()\n",
    "        comm.Recv(recv_sum, source = rank - distance, tag = 0, status = status);\n",
    "#        print (\"Process \", rank, \" receives from \", rank - distance, \" values \", recv_nums)\n",
    "        for j in range(0,int(N/size)):\n",
    "            local_sums[j] += recv_sum[0]\n",
    "    print(\"Process \", rank, \" has \", local_sums)\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (Anaconda)",
   "language": "python",
   "name": "anaconda_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
