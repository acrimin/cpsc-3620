{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <center>Pleasantly Parallel</center>\n",
    "### <center> Linh B. Ngo </center>\n",
    "### <center> CPSC 3620 </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Embarrassingly parallel/naturally parallel/pleasantly parallel\n",
    "- “A computation that can obviously be divided into a number of completely different parts, each of which can be executed by a separate process.”\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- No communication or very little communication among the processes.\n",
    "- Each process can do its tasks without any interaction with the other processes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Python's NumPy library**\n",
    "- Supports n-dimensional array\n",
    "- Provides optimized and vectorized operations on multi-dimensional arrays in large-scale computations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**mpi4py and NumPy**\n",
    "- lower-case communitation routines (send, recv, gather, scatter, reduce) in mpi4py\n",
    "operate on Python's original data types with no optimization\n",
    "- upper-case communication routines (Send, Recv, Bcast, Scatter, Gather, Reduce ...) require\n",
    "Numpy and have syntax similar to the original MPI_xxxx routines in C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n"
     ]
    }
   ],
   "source": [
    "import ipyparallel\n",
    "c=ipyparallel.Client(profile=\"mpicluster\")\n",
    "print(c.ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Upper-case point-to-point: MPI.Send**\n",
    "\n",
    "Comm.Send(buf, dest = 0, tag = 0)\n",
    "\n",
    "Parameters:\t\n",
    "- Comm (MPI comm) – communicator we wish to query\n",
    "- buf (choice) – data to send\n",
    "- dest (integer) – rank of destination\n",
    "- tag (integer) – message tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Upper-case point-to-point: MPI.Recv**\n",
    "\n",
    "Comm.Recv(buf, source = 0, tag = 0, Status status = None)\n",
    "\n",
    "Parameters:\t\n",
    "- Comm (MPI comm) – communicator we wish to query\n",
    "- buf (choice) – initial address of receive buffer\n",
    "- source (integer) – rank of source\n",
    "- tag (integer) – message tag\n",
    "- status (Status) – status of object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "0\n",
      "[0 0 0]\n",
      "[1 2 3]\n",
      "[stdout:1] \n",
      "6\n",
      "[0 0 0]\n",
      "[stdout:2] \n",
      "2\n",
      "[0 0 0]\n",
      "[stdout:3] \n",
      "8\n",
      "[0 0 0]\n",
      "[stdout:4] \n",
      "4\n",
      "[0 0 0]\n",
      "[stdout:5] \n",
      "10\n",
      "[0 0 0]\n",
      "[stdout:6] \n",
      "14\n",
      "[0 0 0]\n",
      "[stdout:7] \n",
      "1\n",
      "[0 0 0]\n",
      "0\n",
      "1000\n",
      "[1 2 3]\n",
      "[stdout:8] \n",
      "12\n",
      "[0 0 0]\n",
      "[stdout:9] \n",
      "3\n",
      "[0 0 0]\n",
      "[stdout:10] \n",
      "5\n",
      "[0 0 0]\n",
      "[stdout:11] \n",
      "7\n",
      "[0 0 0]\n",
      "[stdout:12] \n",
      "9\n",
      "[0 0 0]\n",
      "[stdout:13] \n",
      "13\n",
      "[0 0 0]\n",
      "[stdout:14] \n",
      "11\n",
      "[0 0 0]\n",
      "[stdout:15] \n",
      "15\n",
      "[0 0 0]\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "import numpy\n",
    "from mpi4py import MPI\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank(); print(rank)\n",
    "a = numpy.zeros((3), dtype=numpy.int)\n",
    "status = MPI.Status()\n",
    "print (a)\n",
    "if rank == 0:\n",
    "    a = numpy.array([1,2,3])\n",
    "    print (a)\n",
    "    comm.Send(a, dest=1, tag = 1000)\n",
    "if rank == 1:\n",
    "    comm.Recv(a, source = 0, tag = MPI.ANY_TAG, status = status)\n",
    "    print (status.Get_source())\n",
    "    print (status.Get_tag())\n",
    "    print (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Uppercase collective: MPI.Bcast**\n",
    "\n",
    "Comm.Bcast(buf, root=0)\n",
    "\n",
    "Parameters:\t\n",
    "- Comm (MPI comm) – communicator across which to broadcast\n",
    "- buf (choice) – buffer\n",
    "- root (int) – rank of root operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "0.0\n",
      "Process 2 has the number 0.293651585916\n",
      "[stdout:1] \n",
      "0.0\n",
      "Process 3 has the number 0.293651585916\n",
      "[stdout:2] \n",
      "0.0\n",
      "0.293651585916\n",
      "Process 0 has the number 0.293651585916\n",
      "[stdout:3] \n",
      "0.0\n",
      "Process 1 has the number 0.293651585916\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "import numpy\n",
    "from mpi4py import MPI\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "rand_num = numpy.zeros(1)\n",
    "print (rand_num[0])\n",
    "if rank == 0:\n",
    "    rand_num[0] = numpy.random.uniform(0)\n",
    "    print(rand_num[0])\n",
    "comm.Bcast(rand_num, root = 0)\n",
    "print (\"Process\", rank, \"has the number\", rand_num[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Uppercase collective: MPI.Scatter**\n",
    "\n",
    "Comm.Scatter(sendbuf, recvbuf, root)\n",
    "\n",
    "Parameters:\t\n",
    "- sendbuf (choice) – address of send buffer (significant only at root)\n",
    "- recvbuf (choice) – address of receive buffer\n",
    "- root (int) – rank of sending process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "[  1.   2.   3.   4.   5.   6.   7.   8.   9.  10.  11.  12.  13.  14.  15.\n",
      "  16.  17.  18.  19.  20.  21.  22.  23.  24.  25.  26.  27.  28.  29.  30.\n",
      "  31.  32.  33.  34.  35.  36.  37.  38.  39.  40.  41.  42.  43.  44.  45.\n",
      "  46.  47.  48.]\n",
      "process 0 x: [  1.   2.   3.   4.   5.   6.   7.   8.   9.  10.  11.  12.  13.  14.  15.\n",
      "  16.  17.  18.  19.  20.  21.  22.  23.  24.  25.  26.  27.  28.  29.  30.\n",
      "  31.  32.  33.  34.  35.  36.  37.  38.  39.  40.  41.  42.  43.  44.  45.\n",
      "  46.  47.  48.]\n",
      "process 0 x_local: [ 1.  2.  3.]\n",
      "[stdout:1] \n",
      "process 6 x: None\n",
      "process 6 x_local: [ 19.  20.  21.]\n",
      "[stdout:2] \n",
      "process 2 x: None\n",
      "process 2 x_local: [ 7.  8.  9.]\n",
      "[stdout:3] \n",
      "process 8 x: None\n",
      "process 8 x_local: [ 25.  26.  27.]\n",
      "[stdout:4] \n",
      "process 4 x: None\n",
      "process 4 x_local: [ 13.  14.  15.]\n",
      "[stdout:5] \n",
      "process 10 x: None\n",
      "process 10 x_local: [ 31.  32.  33.]\n",
      "[stdout:6] \n",
      "process 14 x: None\n",
      "process 14 x_local: [ 43.  44.  45.]\n",
      "[stdout:7] \n",
      "process 1 x: None\n",
      "process 1 x_local: [ 4.  5.  6.]\n",
      "[stdout:8] \n",
      "process 12 x: None\n",
      "process 12 x_local: [ 37.  38.  39.]\n",
      "[stdout:9] \n",
      "process 3 x: None\n",
      "process 3 x_local: [ 10.  11.  12.]\n",
      "[stdout:10] \n",
      "process 5 x: None\n",
      "process 5 x_local: [ 16.  17.  18.]\n",
      "[stdout:11] \n",
      "process 7 x: None\n",
      "process 7 x_local: [ 22.  23.  24.]\n",
      "[stdout:12] \n",
      "process 9 x: None\n",
      "process 9 x_local: [ 28.  29.  30.]\n",
      "[stdout:13] \n",
      "process 13 x: None\n",
      "process 13 x_local: [ 40.  41.  42.]\n",
      "[stdout:14] \n",
      "process 11 x: None\n",
      "process 11 x_local: [ 34.  35.  36.]\n",
      "[stdout:15] \n",
      "process 15 x: None\n",
      "process 15 x_local: [ 46.  47.  48.]\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "import numpy\n",
    "from mpi4py import MPI\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank();size = comm.Get_size();LENGTH = 3\n",
    "if rank == 0:\n",
    "    x = numpy.linspace(1,size*LENGTH,size*LENGTH)\n",
    "    print (x)\n",
    "else:\n",
    "    x = None\n",
    "x_local = numpy.zeros(LENGTH)\n",
    "comm.Scatter(x, x_local, root=0)\n",
    "#you should notice that only the root process has a value for x that\n",
    "#is not \"None\"\n",
    "print (\"process\", rank, \"x:\", x)\n",
    "print (\"process\", rank, \"x_local:\", x_local)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Uppercase collective: MPI.Gather**\n",
    "\n",
    "Comm.Gather(sendbuf, recvbuf, root)\n",
    "\n",
    "Parameters:\t\n",
    "- sendbuf (choice) – address of send buffer (significant only at root)\n",
    "- recvbuf (choice) – address of receive buffer\n",
    "- root (int) – rank of receiving process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "[ 6.   7.5  9. ]\n",
      "process 2 x: None\n",
      "process 2 x_local: [ 6.   7.5  9. ]\n",
      "[stdout:1] \n",
      "[  9.   10.5  12. ]\n",
      "process 3 x: None\n",
      "process 3 x_local: [  9.   10.5  12. ]\n",
      "[stdout:2] \n",
      "[ 0.   1.5  3. ]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "process 0 x: [  0.    1.5   3.    3.    4.5   6.    6.    7.5   9.    9.   10.5  12. ]\n",
      "process 0 x_local: [ 0.   1.5  3. ]\n",
      "[stdout:3] \n",
      "[ 3.   4.5  6. ]\n",
      "process 1 x: None\n",
      "process 1 x_local: [ 3.   4.5  6. ]\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "import numpy\n",
    "from mpi4py import MPI\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "size = comm.Get_size()\n",
    "LENGTH = 3\n",
    "x = None\n",
    "x_local = numpy.linspace(rank*LENGTH,(rank+1)*LENGTH, LENGTH)\n",
    "print(x_local)\n",
    "if rank == 0:\n",
    "    x = numpy.zeros(size*LENGTH)\n",
    "    print (x)\n",
    "comm.Gather(x_local, x, root=0)\n",
    "\n",
    "#you should notice that only the root process has a value for x that\n",
    "#is not \"None\"\n",
    "print (\"process\", rank, \"x:\", x)\n",
    "print (\"process\", rank, \"x_local:\", x_local)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Uppercase collective: MPI.Reduce**\n",
    "\n",
    "Comm.Reduce(sendbuf, recvbuf, Op op = MPI.SUM, root = 0)\n",
    "\n",
    "Parameters:\t\n",
    "- Comm (MPI comm) – communicator we wish to query\n",
    "- sendbuf (choice) – address of send buffer\n",
    "- recvbuf (choice) – address of receive buffer (only significant at root)\n",
    "- op (handle) – reduce operation\n",
    "- root (int) – rank of root operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- MPI.MAX:\tmaximum\n",
    "- MPI.MIN:\tminimum\n",
    "- MPI.SUM:\tsum\n",
    "- MPI.PROD:\tproduct\n",
    "- MPI.LAND:\tlogical and\n",
    "- MPI.BAND:\tbit-wise and\n",
    "- MPI.LOR:\tlogical or\n",
    "- MPI.BOR:\tbit-wise or\n",
    "- MPI.LXOR:\tlogical xor\n",
    "- MPI.BXOR:\tbit-wise xor\n",
    "- MPI.MAXLOC:\tmax value and location\n",
    "- MPI.MINLOC:\tmin value and location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] [ 0.]\n",
      "[stdout:1] [ 0.]\n",
      "[stdout:2] [ 3.]\n",
      "[stdout:3] [ 0.]\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "import numpy\n",
    "from mpi4py import MPI\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "rankF = numpy.array(float(rank))\n",
    "total = numpy.zeros(1)\n",
    "comm.Reduce(rankF,total, op=MPI.MAX, root = 0)\n",
    "print (total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "[ 6.   7.5  9. ]\n",
      "[ 0.  0.  0.]\n",
      "[stdout:1] \n",
      "[  9.   10.5  12. ]\n",
      "[ 0.  0.  0.]\n",
      "[stdout:2] \n",
      "[ 0.   1.5  3. ]\n",
      "[ 18.  24.  30.]\n",
      "[stdout:3] \n",
      "[ 3.   4.5  6. ]\n",
      "[ 0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "import numpy\n",
    "from mpi4py import MPI\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "LENGTH = 3\n",
    "x = None\n",
    "x_local = numpy.linspace(rank*LENGTH,(rank+1)*LENGTH, LENGTH)\n",
    "print (x_local)\n",
    "total = numpy.zeros(LENGTH)\n",
    "comm.Reduce(x_local,total, op=MPI.SUM, root = 0)\n",
    "print (total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### <center> Example: Trapezoid Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center> \n",
    "    <img src=\"pictures/trapezoid01.png\" width=\"400\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "N = 8; a = 0; b = 2; h = (b - a)/N;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n"
     ]
    }
   ],
   "source": [
    "# With 4 processors (cores)\n",
    "size = 4; rank = 3\n",
    "local_N = N / size\n",
    "local_a = a + rank * (local_N / N)\n",
    "# local_b = ?\n",
    "print (local_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Which workload goes to which process?\n",
    "```\n",
    "if (rank == i) {\n",
    "\tdo great things\n",
    "}\n",
    "```\n",
    "- Start with small number of processes\n",
    "- Calculation workload assignment manually for each count of processes\n",
    "- Generalize assignment for process i based on sample calculations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:2] The integral is [ 0.3359375]\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "from mpi4py import MPI\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank(); size = comm.Get_size()\n",
    "N = 8; a = 0; b = 1; h = (b - a)/N\n",
    "def f(x):\n",
    "    return x*x\n",
    "local_N = N / size\n",
    "local_a = a + rank * local_N * h\n",
    "partial_result = numpy.zeros(1)\n",
    "sum = numpy.zeros(1)\n",
    "for i in range(0,int(local_N)):\n",
    "    partial_result = partial_result + (f(local_a) + f(local_a + h)) * h / 2\n",
    "    local_a = local_a + h\n",
    "comm.Reduce(partial_result,sum, op=MPI.SUM, root=0)\n",
    "if rank == 0:\n",
    "    print (\"The integral is %s\" % (sum))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### <center> Does each process receive the same amount of work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] Process  2  has  0.099609375\n",
      "[stdout:1] Process  3  has  0.193359375\n",
      "[stdout:2] \n",
      "Process  0  has  0.005859375\n",
      "The integral is 0.3359375\n",
      "[stdout:3] Process  1  has  0.037109375\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "from mpi4py import MPI\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank(); size = comm.Get_size()\n",
    "N = 8; a = 0; b = 1; h = (b - a)/N\n",
    "def f(x):\n",
    "    return x*x\n",
    "local_N = N / size\n",
    "local_a = a + rank * local_N * h\n",
    "partial_result = numpy.zeros(1)\n",
    "sum = numpy.zeros(1)\n",
    "for i in range(0,int(local_N)):\n",
    "    partial_result = partial_result + (f(local_a) + f(local_a + h)) * h / 2\n",
    "    local_a = local_a + h\n",
    "comm.Reduce(partial_result,sum, op=MPI.SUM, root=0)\n",
    "print (\"Process \", rank, \" has \", partial_result[0])\n",
    "if rank == 0:\n",
    "    print (\"The integral is %s\" % (sum[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center> \n",
    "    <img src=\"pictures/static-wa.png\" width=\"400\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center> \n",
    "    <img src=\"pictures/cyclic-wl.png\" width=\"400\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%%px\n",
    "from mpi4py import MPI\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank(); size = comm.Get_size()\n",
    "N = 1000; a = 0; b = 1; h = (b - a)/N\n",
    "def f(x):\n",
    "    return x*x\n",
    "local_N = N / size\n",
    "local_a = ...\n",
    "partial_result = numpy.zeros(1)\n",
    "sum = numpy.zeros(1)\n",
    "for i in range(0,int(local_N)):\n",
    "    partial_result = partial_result + (f(local_a) + f(local_a + h)) * h / 2\n",
    "    local_a = ...\n",
    "comm.Reduce(partial_result,sum, op=MPI.SUM, root=0)\n",
    "print (\"Process \", rank, \" has \", partial_result[0])\n",
    "if rank == 0:\n",
    "    print (\"The integral is %s\" % (sum[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center> \n",
    "    <img src=\"pictures/dynamic-wl.png\" width=\"800\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "import ipyparallel\n",
    "c=ipyparallel.Client(profile=\"mpicluster\")\n",
    "print(c.ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] The integral is [ 0.33333349]\n",
      "[stdout:1] The partial_integral is [ 0.11153683]\n",
      "[stdout:2] The partial_integral is [ 0.11077798]\n",
      "[stdout:3] The partial_integral is [ 0.11101867]\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "from mpi4py import MPI\n",
    "import numpy\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank(); size = comm.Get_size()\n",
    "def f(x):\n",
    "    return x*x\n",
    "partial_result = numpy.zeros(1)\n",
    "local_result = numpy.zeros(1)\n",
    "sum = numpy.zeros(1)\n",
    "h = numpy.zeros(1)\n",
    "a = numpy.zeros(1)\n",
    "status = MPI.Status()\n",
    "\n",
    "if (rank == 0):\n",
    "    N = 1000; a[0]= 0; b = 1; h[0]= (b - a)/N;\n",
    "    comm.Bcast(h, root = 0)\n",
    "    count = 0;\n",
    "    for i in range(1, size):\n",
    "        comm.Send(a,dest = i,tag = 1)\n",
    "        count = count + 1\n",
    "else:\n",
    "    comm.Bcast(h, root = 0)\n",
    "    comm.Recv(a,source = 0, tag = 1,status = status)\n",
    "\n",
    "if (rank != 0):\n",
    "    while True:\n",
    "        local_result[0] = h[0] * (f(a[0]) +  f(a[0] + h[0])) / 2\n",
    "        partial_result[0] += local_result[0];\n",
    "        comm.Send(local_result,dest = 0,tag = 1)      \n",
    "        comm.Recv(a, source = 0, tag = MPI.ANY_TAG, status = status)\n",
    "        if status.Get_tag() != 1:\n",
    "            break\n",
    "            \n",
    "if (rank == 0):\n",
    "    while (count < N):\n",
    "        comm.Recv(partial_result, source = MPI.ANY_SOURCE, tag = MPI.ANY_TAG, status = status)\n",
    "        sum[0] = sum[0] + partial_result[0]\n",
    "        local_a = numpy.array([a + count * h])\n",
    "        comm.Send(local_a, dest = status.Get_source(), tag = 1)\n",
    "        count = count + 1      \n",
    "    for i in range (1,size):\n",
    "        comm.Recv(partial_result, source = MPI.ANY_SOURCE, tag = MPI.ANY_TAG, status = status)\n",
    "        sum = sum + partial_result\n",
    "    for i in range (1,size):\n",
    "        comm.Send(a,dest = i,tag = 0)\n",
    "    print (\"The integral is %s\" % (sum))\n",
    "else:\n",
    "    print (\"The partial_integral is %s\" % (partial_result))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Anaconda 2.5.0 (Python 3)",
   "language": "python",
   "name": "anaconda_2.5.0_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
