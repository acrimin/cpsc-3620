{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <center>Introduction to Message Passing Interface (MPI)</center>\n",
    "### <center> Linh B. Ngo </center>\n",
    "### <center> CPSC 3620 </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### <center>Message Passing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Processes communicate via messages\n",
    "- Messages can be\n",
    "    - Raw data to be used in actual calculations\n",
    "    - Signals and acknowledgements for the receiving processes regarding the workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### <center>History of MPI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "** Early 80s:**\n",
    "- Various message passing environments were developed\n",
    "- Many similar fundamental concepts\n",
    "- N-cube (Caltech), P4 (Argonne), PICL and PVM (Oakridge), LAM (Ohio SC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "** 1992: **\n",
    "- More than 80 reseachers from different institutions in US and Europe agreed to develop and implement a common standard for message passing\n",
    "- First meeting colocated with Supercomputing 1992"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "** After finalization: **\n",
    "- MPI becomes the *de-factor* standard for distributed memory parallel programming\n",
    "- Available on every popular operating system and architecture\n",
    "- Interconnect manufacturers commonly provide MPI implementations optimized for their hardware\n",
    "- MPI standard defines interfaces for C, C++, and Fortran\n",
    "    - Language bindings available for many popular languages (quality varies)\n",
    "    - MPI4PY: Bindings for python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "** 1994: MPI-1 **\n",
    "- Communicators\n",
    "    - Information about the runtime environments\n",
    "    - Creation of customized topologies\n",
    "- Point-to-point communication\n",
    "    - Send and receive messages\n",
    "    - Blocking and non-blocking variations\n",
    "- Collectives\n",
    "    - Broadcast and reduce\n",
    "    - Gather and scatter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "** 1998: MPI-2 **\n",
    "- One-sided communication (non-blocking)\n",
    "    - Get & Put (remote memory access)\n",
    "- Dynamic process management\n",
    "    - Spawn\n",
    "- Parallel I/O\n",
    "    - Multiple readers and writers for a single file\n",
    "    - Requires file-system level support (LustreFS, PVFS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "** 2012: MPI-3 **\n",
    "- Revised remote-memory access semantic\n",
    "- Fault tolerance model\n",
    "- Non-blocking collective communication\n",
    "- Access to internal variables, states, and counters for performance evaluation purposes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### <center> Set up MPI on Palmetto for C/C++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Interactive mode:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`qsub -I -l select=1:ncpus=8:mpiprocs=8:mem=10gb,walltime=01:00:00`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`module load gcc/5.3.0 openmpi/1.10.3`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "*The module load command can be added to a script, which then is to be sourced from inside .bashrc to automate module loading. Calling the module load directly from inside .bashrc is not recommended.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Create a file named **hello.c** inside directory **cpsc3620** with the following content\n",
    "```\n",
    "#include <stdio.h>\n",
    "#include <sys/utsname.h>\n",
    "#include <mpi.h>\n",
    "int main(int argc, char *argv[]){\n",
    "    MPI_Init(&argc, &argv);\n",
    "    struct utsname uts;\n",
    "    uname (&uts);\n",
    "    printf(\"My process is on node %s.\\n\", uts.nodename);\n",
    "\tMPI_Finalize();\n",
    "\treturn 0;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Compile hello.c\n",
    "```\n",
    "mpicc hello.c -o hello\n",
    "```\n",
    "- Run hello.c\n",
    "```\n",
    "mpirun -np 2 ./hello\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### <center> Set up MPI on Palmetto for Python (Interactive via Jupyter Notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Before launching JupyterHub**\n",
    "- Make sure that you have the command ``module load gcc/5.3.0 openmpi/1.10.3`` in your .jhubrc file. If you are using JupyterHub to edit the file, the server will need to be stopped and started again. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Before launching a Jupyter notebook (only need to be done once)**\n",
    "- Install mpi4py by executing ``pip install --user mpi4py`` from a terminal. This needs to be done prior to launching a Jupyter notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Before launching a Jupyter notebook (any time you wish to run interactive MPI inside Jupyter Notebook)**\n",
    "- 1 chunk, 8 cores, 8gb RAM, walltime for one hour\n",
    "- Inside a terminal from JupyterHub(that must be kept open), execute the following commands:\n",
    "\n",
    "```\n",
    "module add gcc/5.3.0 openmpi/1.10.3\n",
    "python /usr/bin/ipcluster start --n <Number of total possible cores> --profile=mpicluster --engines=MPIEngineSetLauncher\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "*You can also create an executable file named ipcluster with the following contents: *\n",
    "\n",
    "```\n",
    "#!/usr/bin/env python\n",
    "\n",
    "from ipyparallel.apps.ipclusterapp import launch_new_instance\n",
    "launch_new_instance()\n",
    "```\n",
    "\n",
    "*With this file set to be executable (chmod 755), you can call it directly: *\n",
    "\n",
    "```\n",
    "./ipcluster start --n <Number of total possible cores> --profile=mpicluster --engines=MPIEngineSetLauncher\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- In the first cell of your Jupyter notebook, type the followings:\n",
    "```\n",
    "import ipyparallel\n",
    "c = ipyparallel.Client(profile=\"mpicluster\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Test the attached cluster by running the following in a cell:\n",
    "```\n",
    "print(c.ids)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Any cell that contains MPI codes must be started with ``%%px``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import ipyparallel\n",
    "c=ipyparallel.Client(profile=\"mpicluster\")\n",
    "print(c.ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%%px\n",
    "from mpi4py import MPI\n",
    "import socket\n",
    "print (\"My process is on node %s\" % (socket.gethostname()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### <center> The working of MPI in a nutshell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- All processes are launched at the beginning of the program execution\n",
    "    - The number of processes are user-speficied\n",
    "    - Typically, this number is matched to the total number of cores available across the entire cluster\n",
    "- All processes have their own memory space and have access to the same source codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Basic parameters available to individual processes: **\n",
    "```\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "size = comm.Get_size()\n",
    "name = MPI.Get_processor_name()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- MPI defines **communicator** groups for point-to-point and collective communications\n",
    "    - Unique IDs (**rank**) are defined for individual processes within a communicator group\n",
    "    - Communications are performed based on these IDs\n",
    "    - Default **global communication** (COMM_WORLD) contains all processes\n",
    "    - For $N$ processes, ranks go from $0$ to $N-1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%%px\n",
    "#!/usr/bin/env python\n",
    "# hello.py\n",
    "from mpi4py import MPI\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "size = comm.Get_size()\n",
    "name = MPI.Get_processor_name()\n",
    "print (\"Hello world from process %s running on host %s out of %s processes\" % \n",
    "       (rank, name, size)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Ranks are used to enforce execution/exclusion of code segments within the original source code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%%px\n",
    "#!/usr/bin/env python\n",
    "# evenodd.py\n",
    "from mpi4py import MPI\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "size = comm.Get_size()\n",
    "name = MPI.Get_processor_name()\n",
    "if (rank % 2 == 0):\n",
    "    print (\"Process %s is even\" % (rank))\n",
    "else:\n",
    "    print (\"Process %s is odd\" % (rank))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Ranks can be used as mean to calculate and distributed workload (data) among the processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%%px\n",
    "#!/usr/bin/env python\n",
    "# workdist.py\n",
    "from mpi4py import MPI\n",
    "import random\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "size = comm.Get_size()\n",
    "name = MPI.Get_processor_name()\n",
    "A = [2,13,4,3,5,1,0,12,10,8,7,9,11,6,15,14]\n",
    "#print (\"Elements %s and %s are assigned to process %s\" \n",
    "#       % (A[rank%15], A[1+rank%15], rank))\n",
    "if (rank < 4):\n",
    "    print (\"Process %s has elements %s\" % (rank, A[(4*rank):(4*rank+4)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Individual processes rely on communication (message passing) to enforce workflow\n",
    "    - Point-to-point Communication\n",
    "    - Collective Communication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### <center> Point-to-Point: Send and Receive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "```\n",
    "comm = MPI.COMM_WORLD\n",
    "```\n",
    "- Sender process:\n",
    "```\n",
    "comm.send(data, dest_rank)\n",
    "```\n",
    "- Receiver process:   \n",
    "```\n",
    "data = comm.recv(source_rank)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "** Original MPI C Syntax: MPI_Send**\n",
    "```\n",
    "int MPI_Send(void *buf, \n",
    "\tint count, \n",
    "\tMPI_Datatype datatype, \n",
    "\tint dest, \n",
    "\tint tag, \n",
    "\tMPI_Comm comm)\n",
    "```\n",
    "\n",
    "- MPI_Datatype may be MPI_BYTE, MPI_PACKED, MPI_CHAR, MPI_SHORT, MPI_INT, MPI_LONG, MPI_FLOAT, MPI_DOUBLE, MPI_LONG_DOUBLE, MPI_UNSIGNED_CHAR\n",
    "- *dest* is the rank of the process the message is sent to\n",
    "- *tag* is an integer identify the message. Programmer is responsible for managing tag\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "** Original MPI C Syntax: MPI_Recv**\n",
    "```\n",
    "int MPI_Recv(\n",
    "\tvoid *buf, \n",
    "\tint count, \n",
    "\tMPI_Datatype datatype, \n",
    "\tint source, \n",
    "\tint tag, \n",
    "\tMPI_Comm comm,\n",
    "\tMPI_Status *status)\n",
    "```\n",
    "\n",
    "- MPI_Datatype may be MPI_BYTE, MPI_PACKED, MPI_CHAR, MPI_SHORT, MPI_INT, MPI_LONG, MPI_FLOAT, MPI_DOUBLE, MPI_LONG_DOUBLE, MPI_UNSIGNED_CHAR\n",
    "- *source* is the rank of the process from which the message was sent.\n",
    "- *tag* is an integer identify the message. MPI_Recv will only place data in the buffer if the tag from MPI_Send matches. The constant MPI_ANY_TAG may be used when the source tag is unknown or not important. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%%px\n",
    "#!/usr/bin/env python\n",
    "# sendrecv.py\n",
    "from mpi4py import MPI\n",
    "import random\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "if (rank == 0):\n",
    "    send_pkg = random.random()\n",
    "    print (send_pkg)\n",
    "    comm.send(send_pkg, dest = 1, tag = 1)\n",
    "if (rank == 1):\n",
    "    recv_pkg = 0\n",
    "    recv_pkg = comm.recv(source = 0, tag = 1)\n",
    "    print (recv_pkg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Blocking risks**\n",
    "- Send data larger than available network buffer (Blocking send)\n",
    "- Lost data (or missing sender) leading to receiver hanging indefinitely (Blocking receive)\n",
    "\n",
    "**Data types**\n",
    "- MPI4PY supports all default MPI's data types\n",
    "- MPI4PY uses *pickle* to facilitate sending and receiving of complex data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%%px\n",
    "#!/usr/bin/env python\n",
    "# sendrecv2.py\n",
    "from mpi4py import MPI\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "if rank == 0:\n",
    "    data = {'class': 'cpsc3620', 'semester': 'Spring 2017', \n",
    "            'enrollments': 40}\n",
    "    comm.send(data, dest=1, tag=11)\n",
    "elif rank == 1:\n",
    "    data = comm.recv(source=0, tag=11)\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%%px\n",
    "#!/usr/bin/env python\n",
    "# sendrecv3.py\n",
    "from mpi4py import MPI\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "if rank == 0:\n",
    "    data = [1,2,3,4]\n",
    "    comm.send(data, dest=1, tag=11)\n",
    "elif rank == 1:\n",
    "    data = comm.recv(source=0, tag=11)\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### <center> Collective Communication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Must involve ALL processes within the scope of a communicator\n",
    "- Unexpected behavior, including programming failure, if even one process does not participate\n",
    "- Types of collective communications:\n",
    "    - Synchronization: barrier\n",
    "    - Data movement: broadcast, scatter/gather\n",
    "    - Collective computation (aggregate data to perform computation): Reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center> <img src=\"pictures/mpi-collective.png\" width=\"700\"/> \n",
    "<sub> *https://computing.llnl.gov/tutorials/mpi/* </sub>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**broadcast:**\n",
    "```\n",
    "comm = MPI.COMM_WORLD\n",
    "```\n",
    "- All processes:\n",
    "```\n",
    "<buffer at receiving process> = comm.bcast(<original data>, root=<root process>)\n",
    "```\n",
    "- *root* process is the one that has the original data initially. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "```\n",
    "int MPI_Bcast(\n",
    "\tvoid *buf, \n",
    "\tint count, \n",
    "\tMPI_Datatype datatype, \n",
    "\tint root, \n",
    "\tMPI_Comm comm);\n",
    "```\n",
    "- Don’t need to specify a TAG or DESTINATION\n",
    "- Must specify the SENDER (root)\n",
    "- Blocking call for all processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%%px\n",
    "#!/usr/bin/env python\n",
    "# bcast.py\n",
    "from mpi4py import MPI\n",
    "comm = MPI.COMM_WORLD; rank = comm.Get_rank();\n",
    "if rank == 0:\n",
    "    data = 2\n",
    "elif (rank != 1):\n",
    "    data = -1\n",
    "else:\n",
    "    data = -2\n",
    "print (\"%s: %s\" % (rank, data))\n",
    "if (rank != 1):\n",
    "    data = comm.bcast(data, root=0)\n",
    "    print (\"%s: %s\" % (rank, data))\n",
    "else:\n",
    "    data1 = comm.bcast(data, root=0)\n",
    "    print (\"%s: %s\" % (rank, data))\n",
    "if (rank == 1):\n",
    "    print(\"%s: %s\" % (rank, data1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%%px\n",
    "#!/usr/bin/env python\n",
    "# bcast2.py\n",
    "from mpi4py import MPI\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "if rank == 0:\n",
    "    data = {'key1' : [7, 2.72, 2+3j],\n",
    "            'key2' : ( 'abc', 'xyz')}\n",
    "else:\n",
    "    data = None\n",
    "data = comm.bcast(data, root=0)\n",
    "print (\"process %s\" % (rank))\n",
    "print (rank,data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**scatter:**\n",
    "```\n",
    "comm = MPI.COMM_WORLD\n",
    "```\n",
    "- All processes:\n",
    "```\n",
    "<buffer at receiving process> = comm.scatter(<original array>, root=<root process>)\n",
    "```\n",
    "- *root* process is the one that has the original data array initially. \n",
    "- Data are divided according to rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "** Original MPI C Syntax: MPI_Scatter**\n",
    "```\n",
    "int MPI_Scatter(\n",
    "\tvoid *sendbuf, \n",
    "\tint sendcount, \n",
    "\tMPI_Datatype sendtype, \n",
    "\tvoid *recvbuf,\n",
    "\tint recvcnt,\n",
    "\tMPI_Datatype recvtype,\n",
    "\tint root, \n",
    "\tMPI_Comm comm);\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%%px\n",
    "#!/usr/bin/env python\n",
    "# scatter.py\n",
    "from mpi4py import MPI\n",
    "comm = MPI.COMM_WORLD\n",
    "size = comm.Get_size();rank = comm.Get_rank(); print(rank)\n",
    "\n",
    "if rank == 0:\n",
    "    data = [(i+1)**2 for i in range(size)]\n",
    "    print (data)\n",
    "else:\n",
    "    data = None\n",
    "partial_data = comm.scatter(data, root=0)\n",
    "print (data)\n",
    "print (partial_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%%px\n",
    "#!/usr/bin/env python\n",
    "# scatter2.py\n",
    "from mpi4py import MPI\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "if rank == 0:\n",
    "    data = [{'key1' : [7, 2.72, 2+3j]},\n",
    "            {'key2' : ( 'abc', 'xyz')},\n",
    "            {'key3' : ( 'abc', 'xyz')},\n",
    "            {'key4' : ( 'cde', 'xyz')}]\n",
    "else:\n",
    "    data = None\n",
    "data = comm.scatter(data, root=0)\n",
    "print (\"%s: %s\" % (rank, data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**gather:**\n",
    "```\n",
    "comm = MPI.COMM_WORLD\n",
    "```\n",
    "- All processes:\n",
    "```\n",
    "<buffer at sending process> = comm.gather(<final array>, root=<root process>)\n",
    "```\n",
    "- *root* process is the one that receives the original data array initially. \n",
    "- Data arrive and are sorted at *root* according to rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "** Original MPI C Syntax: MPI_Gather**\n",
    "```\n",
    "int MPI_Gather(\n",
    "\tvoid *sendbuff, \n",
    "\tint sendcount, \n",
    "\tMPI_Datatype sendtype, \n",
    "\tvoid *recvbuff,\n",
    "\tint recvcnt,\n",
    "\tMPI_Datatype recvtype,\n",
    "\tint root, \n",
    "\tMPI_Comm comm);\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%%px\n",
    "#!/usr/bin/env python\n",
    "# gather.py\n",
    "from mpi4py import MPI\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "size = comm.Get_size()\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "data = (rank+1)**2\n",
    "print (\"%s: %s\" % (rank, data))\n",
    "all_data = comm.gather(data, root=0)\n",
    "if rank == 0:\n",
    "    print (\"%s: %s\" % (rank, data))\n",
    "    print (all_data)\n",
    "else:\n",
    "    print (\"%s: %s\" % (rank, data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**reduce**\n",
    "```\n",
    "comm = MPI.COMM_WORLD\n",
    "```\n",
    "- All processes:\n",
    "```\n",
    "<final result at sending process> = comm.reduce(<data to be reduced>, op=MPI.<operation>, root=<root process>)\n",
    "```\n",
    "- *root* process is the one that receives the final reduced data initially. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "** Original MPI C Syntax: MPI_Reduce**\n",
    "```\n",
    "int MPI_Reduce(\n",
    "\tvoid *sendbuf, \n",
    "\tvoid *recvbuff,\n",
    "\tint count, \n",
    "\tMPI_Datatype datatype, \n",
    "\tMPI_OP op,\n",
    "\tint root, \n",
    "\tMPI_Comm comm);\n",
    "```\n",
    "- MPI_Op may be MPI_MIN, MPI_MAX, MPI_SUM, MPI_PROD (twelve total)\n",
    "- Programmer may add operations, must be commutative and associative\n",
    "- If count > 1, then operation is performed element-wise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%%px\n",
    "#!/usr/bin/env python\n",
    "# reduce.py\n",
    "from mpi4py import MPI\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "sum = comm.reduce(rank, op=MPI.SUM, root=0)\n",
    "\n",
    "if rank == 0:\n",
    "    print (\"The reduction is %s\" % (sum))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
